---
title: "Classification and Predication: Stock Prices"
output: html_document
date: "2023-04-22"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(ggcorrplot)
library(dplyr)
library(timetk)
library(ggplot2)
library(gridExtra)
library(Metrics)
library(caret)
library(factoextra)
library(cluster)
```

## 1. Title & Introduction

### **Classification and Prediction: Stock Prices**

By: Abhinav Bichal, Wei-Yu Chiang

### **Introduction**

Our data set contains variables of many different stocks with their prices, dates, volume, and a handful of stock indicators. These indicators are our predictor variables and are widely used to analyze stocks, such as the simple moving average, which takes a stock's average price in the past certain number of days, which results in a line. The outcome variable we will try to predict is the closing prices of stocks at the end of the day. All of our stock indicators were personally coded by us and applied to our list of stock that we obtained from yahoo finance. The data is constantly up to date as we are pulling information directly from yahoo finance through an API. We chose this topic because investing is important for retirement and personal financial goals. We wanted to investigate stock market investing with data and how well these stock indicators could predict price. We expect most of our indicators to be strongly correlated with the stock price because they are derived from them. We want to focus on the regression equations that we obtain to analyze how close we can predict the next day's price

**Wei-Yu's Research Question:**

How accurately can we predict the stock price next day from stock indicators with linear regression?

**Abhinav's Research Question:**

Given a particular stock based on sentimental value, can we predict if the price will increase or decrease?

## 2. Exploratory Data Analysis

```{r}
#grabbing the data
data <- read.csv('data.csv')

# reformatting data



names(data) <- tolower(names(data))


#rename columns
data <- data %>%
  na.omit %>%
  rename('adj_close' = 'adj.close',
         'macd_signal' = 'macd.signal')

data <- data %>%
  separate(col='date',into =c('month','day','year'),sep='\\/') %>%
  unite(date,c('year','month','day'),sep = '-')
  

data$date <- as.Date(data$date)

data 


```

```{r}

aapl <- data %>%
  filter(ticker=='AAPL')

#making a column for if there was positive or negative gain from the day before

#creates a lagged column

aapl <- aapl %>% 
  mutate(lead_adj_close = lead(adj_close,n=1)) %>%
  mutate(diff = lead_adj_close-adj_close) %>%
  mutate(pos_neg = ifelse(diff > 0,'pos','neg')) %>%
  #select(-lag_adj_close) %>%
  na.omit
  
```

```{r}


#demonstrating correlation of variables with only Apple stocks
aapl %>%
  select(-date,-ticker,-pos_neg) %>%
  cor %>%
  ggcorrplot
```

### **Correlation Matrix**

The highest correlated variables are the SMA with open, low, high close, and adjusted close which are attributes of a stock price. The same can also be seen with the EMA and stock information. The lowest correlated variables are MACD, MACD SIGNAL, Diff, and RSI against stock prices.

# **Visualizations of Relationships cross the Variables**

### **Wei-Yu's Visualizations**

```{r}

aapl_price <- aapl %>%
  ggplot()+
  geom_line(aes(x = date,y=adj_close))

aapl_rsi <- aapl %>%
  ggplot(aes(x=date,y=rsi)) +
  geom_line()

grid.arrange(aapl_price,aapl_rsi,ncol=1)
```

**Relative Strength Index**

The RSI is separated from the graph because it is calculated from the percentage gain/loss of stock prices. Typically, when the RSI is above 70 then the stock is overbought and when the score is below 30 it is oversold. People usually want to sell stocks when it is overbought and buy when the stocks are oversold. Here we can see instances of when the RSI score is very high and is followed with a downward trend because it is overbought.

![](images/Capture.JPG)

```{r}

data %>% 
  filter(ticker=='AAPL') %>%
  ggplot() +
  geom_line(aes(x=date,y=adj_close)) +
  geom_line(aes(x=date,y=sma),color='red')

```

**Simple Moving Average**

The simple moving average is calculated based on the prices of previous days. It computes an average and overlaps onto the line graph of price because it is specific to that price. This tool is used to look at upward and downward trends as it allows people to see how the price is performing based on an average. For example, around 2021-07, price (black line) stays above the SMA (red line) for many days because it keeps performing better than its average. We can watch out for when the price crosses the SMA which could indicate price changing directions.

### **Abhinav's Visualizations**

## 3. Prediction and Cross-validation

### **Wei-Yu's Prediction**

```{r}

fit_lin <- lm(diff~sma + ema + macd + rsi + volume + macd_signal + adj_close, data = aapl)


pred_lin <- aapl %>%
  mutate(predictions = predict(fit_lin)) %>%
  select(adj_close,predictions,date,diff)

pred_lin %>% 
  ggplot() +
  geom_line(aes(x=date,y=diff)) +
  geom_line(aes(x=date,y=predictions),color='red')

rmse(pred_lin$adj_close,pred_lin$predictions)

summary(fit_lin)$r.squared
```

**(First 60 days of graph above)**

```{r}
pred_lin %>% 
  slice(1:60) %>%
  ggplot() +
  geom_line(aes(x=date,y=diff)) +
  geom_line(aes(x=date,y=predictions),color='red')
```

### Cross-validation

```{r}

TimeControl <- trainControl(method = 'timeslice',
                            initialWindow = 55,
                            horizon = 55)


train(adj_close~sma + ema + macd + rsi + volume + macd_signal,
      data = aapl,
      method = 'lm',
      trControl = TimeControl
)


```

## 4. Dimensionality Reduction

**Additional Data Preparation**

```{r}

aapl$volume <- as.double(aapl$volume)

aapl_scaled <- aapl %>%
  select_if(is.double) %>%
  select(!(1:6)) %>%
  select(-diff) %>%
  scale %>%
  as.data.frame

head(aapl_scaled)
```

```{r}
pca <- aapl_scaled %>%
  prcomp


fviz_eig(pca, addlabels = TRUE, ylim = c(0, 60))

```

**We will keep the first two principal components for total of 79.6% explained variance.**

```{r}
fviz_pca_ind(pca) 
```

## 5. Clustering

**PAM Clustering**

```{r}

fviz_nbclust(aapl_scaled, pam, method = "silhouette")
```

**We will choose to use two clusters.**

```{r}
pam_results <- aapl_scaled %>%
  pam(k = 2)

fviz_cluster(pam_results)

```

```{r}
aapl  %>%
  mutate(cluster = as.factor(pam_results$clustering)) %>%
  group_by(cluster) %>%
  summarize_if(is.numeric, mean, na.rm = T)
```
